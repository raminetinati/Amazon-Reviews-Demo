{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Reviews - Sentiment Model Experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "import gzip\n",
    "from io import BytesIO\n",
    "import zipfile\n",
    "import random\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.metrics import classification_report\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configs and Global Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = {\n",
    "    'aws_region' :  'us-east-1',\n",
    "    'bucket_name': 'demos-amazon-reviews',\n",
    "    'prefix' : 'preprocessed_reviews', #only use this if you want to have your files in a folder \n",
    "    'index_key' : 'review_date_str'\n",
    "    \n",
    "}\n",
    "\n",
    "global_vars = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Setup\n",
    "\n",
    "Setting up the environment involves ensuring all the corret session and IAM roles are configured. We also need to ensure the correct region and bucket is made available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket already exists\n"
     ]
    }
   ],
   "source": [
    "def setup_env(configs, global_vars):\n",
    "    \n",
    "    sess = sagemaker.Session()\n",
    "    \n",
    "    role = get_execution_role()\n",
    "\n",
    "    AWS_REGION = configs['aws_region']\n",
    "    s3 = boto3.resource('s3')\n",
    "\n",
    "    s3_bucket = s3.Bucket(configs['bucket_name'])\n",
    "\n",
    "    if s3_bucket.creation_date == None:\n",
    "    # create S3 bucket because it does not exist yet\n",
    "        print('Creating S3 bucket {}.'.format(bucket))\n",
    "        resp = s3.create_bucket(\n",
    "            ACL='private',\n",
    "            Bucket=bucket\n",
    "        )\n",
    "    else:\n",
    "        print('Bucket already exists')\n",
    "        \n",
    "    global_vars['role'] = role\n",
    "    global_vars['sess'] = sess\n",
    "    global_vars['s3'] = s3\n",
    "    global_vars['s3_bucket'] = s3_bucket\n",
    "    \n",
    "    return global_vars\n",
    "\n",
    "global_vars = setup_env(configs, global_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Data Manifest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_manifest(global_vars):\n",
    "    \n",
    "    manifest_train = []\n",
    "    manifest_val = []\n",
    "    \n",
    "    idx = 0\n",
    "    conn = boto3.client('s3')  # again assumes boto.cfg setup, assume AWS S3\n",
    "    \n",
    "    for file in s3.objects.all():#(Bucket=bucket_name, Prefix=data_path)['Contents']:\n",
    "        path = file.key\n",
    "#         print(path)\n",
    "        if ('.JPEG' in path) or ('.jpeg' in path):\n",
    "            if 'training' in path:\n",
    "                man = {}\n",
    "                relative_path = path.replace('training/','')\n",
    "#                 print(relative_path)\n",
    "                if 'damage' in path:\n",
    "                    data_class = 1.0\n",
    "                else:\n",
    "                    data_class = 0.0\n",
    "                man = {'idx':idx, 'class': data_class, 'path':relative_path, 'path_with_prefix':path}\n",
    "                manifest_train.append(man)\n",
    "                \n",
    "            if 'validation' in path:\n",
    "                man = {}\n",
    "                relative_path = path.replace('validation/','')\n",
    "                if 'damage' in path:\n",
    "                    data_class = 1.0\n",
    "                else:\n",
    "                    data_class = 0.0\n",
    "                man = {'idx':idx, 'class': data_class, 'path':relative_path, 'path_with_prefix':path}\n",
    "                manifest_val.append(man)\n",
    "            idx += 1\n",
    "    print('Training Dataset Size {}, Validation Size {}'.format(len(manifest_train), len(manifest_val)))\n",
    "    \n",
    "    ##Create Augmented JSON Record file\n",
    "    aug_train = []\n",
    "    for x in manifest_train:\n",
    "        absolute_path = 's3://{}/{}'.format(bucket_name, x['path_with_prefix'])\n",
    "        \n",
    "        dic = {'source-ref':absolute_path, 'class': str(x['class'])}\n",
    "        aug_train.append(dic)\n",
    "\n",
    "    with open('train_manifest.json', 'w') as fout:\n",
    "        for x in aug_train:\n",
    "            fout.write(json.dumps(x)+'\\n')\n",
    "            #json.dump(aug_train, fout, indent=4)\n",
    "    \n",
    "    val_train = []\n",
    "    for x in manifest_val:\n",
    "        absolute_path = 's3://{}/{}'.format(bucket_name, x['path_with_prefix'])\n",
    "        \n",
    "        dic = {'source-ref':absolute_path, 'class': str(x['class'])}\n",
    "        val_train.append(dic)\n",
    "\n",
    "    with open('val_manifest.json', 'w') as fout:\n",
    "         for x in val_train:\n",
    "            fout.write(json.dumps(x)+'\\n')\n",
    "\n",
    "    return manifest_train, manifest_val \n",
    "            \n",
    "manifest_train, manifest_val  = create_dataset_manifest(global_vars)   \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
